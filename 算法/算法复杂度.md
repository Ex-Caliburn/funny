#

## 前言

### O(1)

```js
    console.log(i)
```

### O(n)

```js
for (let i = 0; i < n; i++) {
    console.log(i)
}
```

### O(n^2)

```js
for (let i = 0; i < n; i++) {
    for (let j = 0; j < n; j++) {
       console.log(i, j)
    }
}
```

### O(logN)

```js
for (let i = 0; i < n; i = i * 2) {
    console.log(i)
} 
```

### O(k^N)

```js
function fib(n) {
  if (n < 2) return n
  return fib(n - 1) + fib(n - 2)
}
```

### 关于算法的时间复杂度很多都用包含O(logN)这样的描述，但是却没有明确说logN的底数究竟是多少

复杂度很多都用包含O(logN)

算法中log级别的时间复杂度都是由于使用了分治思想,这个底数直接由分治的复杂度决定。
如果采用二分法,那么就会以2为底数,三分法就会以3为底数,其他亦然。
不过无论底数是什么,log级别的渐进意义是一样的。
也就是说该算法的时间复杂度的增长与处理数据多少的增长的关系是一样的。

我们先考虑O(logx(n))和O(logy(n))，x!=y，我们是在考虑n趋于无穷的情况。
求当n趋于无穷大时logx(n)/logy(n)的极限可以发现，极限等于lny/lnx，也就是一个常数，
也就是说，在n趋于无穷大的时候，这两个东西仅差一个常数。
所以从研究算法的角度log的底数不重要。

最后，结合上面，我也说一下关于大O的定义（算法导论28页的定义），
注意把这个定义和高等数学中的极限部分做比较，
显然可以发现，这里的定义正是体现了一个极限的思想，
假设我们将n0取一个非常大的数字，
显然，当n大于n0的时候，我们可以发现任意底数的一个对数函数其实都相差一个常数倍而已。
所以书上说写的O（logn）已经可以表达所有底数的对数了，就像O(n^2)一样。
没有非常严格的证明，不过我觉得这样说比较好理解，如果有兴趣证明，完全可以参照高数上对极限趋于无穷的证明。

## 总结

### 参考文献
