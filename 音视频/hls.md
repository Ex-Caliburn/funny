# hls

## 前言

网络协议 HTTP

封装格式 MEPG-2 TS

编码格式 视频编码格式为H.264，音频编码格式为MP3、AAC、AC-3或EC-3

索引文件 M3U8

### 原理

从概念上讲，HTTP Live Streaming由三个部分组成：服务器组件，分发组件和客户端软件。

的服务器组件是负责采取的媒体输入流和数字编码它们，以适合于递送的格式将它们封装，以及制备所述包封的媒体分发。

该分配组件包括标准的Web服务器。他们负责接受客户端请求，并将准备好的媒体和相关资源交付给客户端。对于大规模分发，还可以使用边缘网络或其他内容传递网络。

该客户端软件负责确定适当的媒体请求，下载这些资源，然后重新装配即可，使得介质可以在一个连续的数据流被呈现给用户。客户端软件包含在iOS 3.0和更高版本以及装有Safari 4.0或更高版本的计算机上。

在典型配置中，硬件编码器接受音频视频输入，将其编码为H.264视频和AAC音频，然后以MPEG-2传输流输出，然后由软件分解为一系列简短的媒体文件流分割器。这些文件放置在Web服务器上。分段器还创建并维护一个包含媒体文件列表的索引文件。索引文件的URL在Web服务器上发布。客户端软件读取索引，然后按顺序请求列出的媒体文件并显示它们，而各段之间没有任何暂停或间隔。

一个简单的HTTP流配置示例如图

![alt](https://developer.apple.com/library/archive/documentation/NetworkingInternet/Conceptual/StreamingMediaGuide/art/transport_stream_2x.png)

### 简单流程

1 http 请求 m3u8 的 url。

2 服务端返回一个 m3u8 的播放列表，这个播放列表是实时更新的，一般一次给出5段数据的 url。

3 客户端解析 m3u8 的播放列表，再按序请求每一段的 url，获取 ts 数据流。

### m3u8

M3U8 是 Unicode 版本的 M3U，用 UTF-8 编码。"M3U" 和 "M3U8" 文件都是苹果公司使用的 HTTP Live Streaming（HLS） 协议格式的基础

一个.M3U8文件是一个可扩展的播放列表文件格式。这是一个包含UTF-8编码文本的m3u播放列表。m3u文件格式是事实上的标准播放列表格式，适用于携带媒体文件URL列表。这是用作HTTP Live Streaming索引文件的格式。

### ts

全称为MPEG2-TS。ts即"Transport Stream"的缩写。MPEG2-TS格式的特点就是要求从视频流的任一片段开始都是可以独立解码的

TS（Transport Stream）: 动态文件流

一个.ts文件包含一个MPEG-2传输流。这是一种文件格式，封装了一系列编码的媒体样本，通常是音频和视频。该文件格式支持多种压缩格式，包括MP3音频，AAC音频，H.264视频等。但是，Apple HTTP Live Streaming实现当前不支持所有压缩格式。

### apple 推荐

apple 官方建议 m3u8 播放列表数3， ts 片段时长 10s，理论上延迟就有30s，还是太长了，我们尽量缩小 播放列表到1个 和ts时长到1s，对于服务器压力会越大，网速慢的时候会造成更多的缓冲

媒体文件应保留多长时间？

- 要考虑的主要点是，较短的段会导致索引文件的刷新频率更高，这可能会给客户端带来不必要的网络开销。较长的段会延长广播的固有延迟和初始启动时间。对于大多数广播内容，每个文件10秒的媒体持续时间似乎达到了合理的平衡。

连续不断的会话中，索引文件中应列出多少个文件 ？

- 正常建议为3，但最佳数量可能会更大。

- 选择最佳数量时要考虑的重要点是，在实时会话期间可用的文件数量会限制客户端在执行播放/暂停和搜索操作时的行为。列表中的文件越多，客户端可以在不失去广播位置的情况下暂停的时间就越长，加入流时新客户端开始在广播中返回的位置越远，客户端可以搜索的时间范围越广。代价是较长的索引文件会增加网络开销，在直播期间，客户端都会定期刷新索引文件，因此即使索引文件通常很小，它也确实会累加。

### 其他优化方式

如何减少开销并降低比特率？

- 使用更高效的编码器可以减少开销，调整编码器设置也可以。

m3u8 无法走CDN， m3u8 必须动态更新，ts 可以走 CDN。

## 总结

路由器，NAT或防火墙设置不太可能禁止使用HTTP。无需打开默认情况下通常关闭的端口。因此，内容更可能在更多位置到达客户端，而无需进行特殊设置。更多内容分发网络也支持HTTP，这可能会影响大型分发模型的成本。通常，与RTP / RTSP相比，更多可用的硬件和软件在未经修改的情况下以及与HTTP一起使用时的预期用途。使用PHP等工具自定义HTTP内容交付的专业知识也越来越广泛。

此外，Safari和iOS上的媒体播放器框架均支持HTTP Live Streaming。不支持RTSP流。

HLS 协议本质还是一个个的 HTTP 请求 / 响应，所以适应性很好，不会受到防火墙影响

虽然HLS有上述优势，但也同时存在延迟过大的劣势。采用HLS直播的视频流延时一般在10秒以上，使用推荐配置时延迟大概在30s，而RTMP直播的延迟最低可达到3、4秒，因此，在对实时性要求较高的场合，如互动直播，就要慎用HLS了。

HLS：延迟主要来自编码解码时产生延迟、网络延迟、CDN 分发延迟。由于它是切片协议，延迟分两大块，一个是服务端有切片缓冲延迟，另一个是在播放端防抖缓冲会有延迟。切片的大小和数量都会 HLS 影响延迟大小，一般在十秒以上。

RTMP/HTTP-FLV: 目前国内大部分厂家在用的 RTMP，它相对于 HLS 在服务端做了优化。RTMP 服务端不再进行切片，而是分别转发每一帧，CDN 分发延迟非常小。
RTMP 延迟主要来自播放端防抖缓冲：为提升弱网环境下抖动时直播的流畅度，缓冲延迟一般有五到十秒。这两类协议都是基于 TCP，国内厂商基本上已经将 RTMP over TCP 的延迟做到的极致，如果一个协议仍然基于 TCP 优化延迟，效果上很难优于目前的 RTMP 。

TCP 由于其自身的一些特性，并不适用于低延迟直播场景，主要原因如下：
重传慢：TCP 的 ACK 确认机制，丢包后发送侧超时重传，超时时间一般200ms，会造成接收侧帧抖动。
拥塞判断不准确：基于丢包的拥塞控制算法无法准确判断拥塞，丢包并不等于拥塞；也会造成发送链路 bufferbloat，链路 RTT 增大，延迟增加。
灵活性差：这是最主要原因，TCP 拥塞控制算法在操作系统内核层实现，优化成本较高，移动端只有利用系统已有的优化。

### videojs兼容方案

步骤

1. 通过http请求获取索引文件
2. 将传输的视频流二进制数据封装成可直接播放的视频格式
3. videojs-contrib-hls是利用video.js里SWF的一个特殊模块，将视频二进制数据打包成flv格式hls.js是转化成MP4格式
4. 使用appendBuffer将视频片段添加到SourceBuffer中


### Media Source Extensions API

媒体源扩展（MSE）实现后，情况就不一样了。MSE 使我们可以把通常的单个媒体文件的 src 值替换成引用 MediaSource 对象（一个包含即将播放的媒体文件的准备状态等信息的容器），以及引用多个 SourceBuffer 对象（代表多个组成整个串流的不同媒体块）的元素。MSE 让我们能够根据内容获取的大小和频率，或是内存占用详情（例如什么时候缓存被回收），进行更加精准地控制。 它是基于它可扩展的 API 建立自适应比特率流客户端（例如DASH 或 HLS 的客户端）的基础。

在现代浏览器中创造能兼容 MSE 的媒体（assets）非常费时费力，还要消耗大量计算机资源和能源。此外，还须使用外部实用程序将内容转换成合适的格式。虽然浏览器支持兼容 MSE 的各种媒体容器，但采用 H.264 视频编码、AAC 音频编码和 MP4 容器的格式是非常常见的，且一定兼容。MSE 同时还提供了一个 API，用于运行时检测容器和编解码是否受支持。

### 参考文献

1. <https://developer.apple.com/library/archive/documentation/NetworkingInternet/Conceptual/StreamingMediaGuide/HTTPStreamingArchitecture/HTTPStreamingArchitecture.html#//apple_ref/doc/uid/TP40008332-CH101-SW2>
2. <https://blog.csdn.net/u011857683/article/details/84863250>
3. <https://segmentfault.com/a/1190000009859281>
4. <https://www.zhihu.com/question/25497090>
5. <https://developer.mozilla.org/zh-CN/docs/Web/API/Media_Source_Extensions_API>
